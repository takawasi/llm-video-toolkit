# 攻略本: llm-video-toolkit 動画編集ユースケース

**用途**: LLMがこのMDを参照して動画タスクに対応する
**参照タイミング**: 動画編集/変換/分析の依頼を受けた時
**更新**: 2025-12-10（Gemini Pro連携追加）

---

## 0. 使い方

```
1. ユーザーの「やりたいこと」を把握
2. 該当カテゴリを探す
3. 自然言語指示例を参考にコマンド実行
4. 連携が必要なら「連携コンボ」参照
```

**ツール実行パス**: `/home/heint/CB/プロジェクト/llm-video-toolkit/`

```bash
cd /home/heint/CB/プロジェクト/llm-video-toolkit
source venv/bin/activate
python main.py [コマンド]
```

---

## 1. ファイル変換・圧縮

### 1.1 解像度変更

**自然言語指示例**:
- 「720pに変換して」
- 「4Kにアップスケール」
- 「1080pに縮小」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "720pに変換" -i input.mp4 -o output.mp4
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -vf scale=-1:720 -c:a copy output.mp4
```

---

### 1.2 フォーマット変換

**自然言語指示例**:
- 「MP4に変換」
- 「WebMに変換」
- 「MOVからMP4に」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "MP4に変換" -i input.mov -o output.mp4
```

---

### 1.3 ファイルサイズ圧縮

**自然言語指示例**:
- 「ファイルサイズを半分に」
- 「10MB以下に圧縮」
- 「SNS投稿用に軽くして」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "ファイルサイズを半分に圧縮" -i input.mp4 -o output.mp4
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -c:v libx264 -crf 28 -c:a aac -b:a 128k output.mp4
```

**備考**: CRF値が高いほど圧縮率高（画質低下）。18-28が実用範囲。

---

### 1.4 縦動画変換（横→縦）

**自然言語指示例**:
- 「縦動画にして」
- 「9:16に変換」
- 「TikTok用に縦にクロップ」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "9:16の縦動画にクロップ" -i input.mp4 -o output.mp4
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -vf "crop=ih*9/16:ih,scale=1080:1920" output.mp4
```

---

## 2. 切り出し・カット

### 2.1 時間指定切り出し

**自然言語指示例**:
- 「最初の30秒だけ」
- 「1:30から2:00まで切り出し」
- 「最後の1分をカット」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "1:30から2:00まで切り出し" -i input.mp4 -o clip.mp4
```

**生成コマンド例**:
```
ffmpeg -ss 00:01:30 -to 00:02:00 -i input.mp4 -c copy clip.mp4
```

---

### 2.2 バズ箇所自動抽出

**自然言語指示例**:
- 「この動画からバズりそうな部分を5つ切り出して」
- 「ショート動画用に面白い部分を抽出」
- 「切り抜き候補を出して」

**使用ツール**: clip-cutter

**実行**:
```bash
python main.py clip -i long_video.mp4 -n 5 -o ./clips
```

**出力**:
- `clips/clip_001.mp4` 〜 `clip_005.mp4`
- `clips/metadata.json`（各クリップの理由付き）

**パラメータ調整**:
```bash
# 最小30秒、最大90秒で3つ
python main.py clip -i video.mp4 -n 3 --min-duration 30 --max-duration 90
```

---

### 2.3 GIF作成

**自然言語指示例**:
- 「この部分をGIFに」
- 「10秒から15秒をGIF化」
- 「ループGIF作って」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "10秒から15秒をGIFに変換" -i input.mp4 -o output.gif
```

**生成コマンド例**:
```
ffmpeg -ss 10 -t 5 -i input.mp4 -vf "fps=15,scale=480:-1" -loop 0 output.gif
```

---

## 3. 音声操作

### 3.1 音声抽出（MP3化）

**自然言語指示例**:
- 「音声だけ抽出して」
- 「MP3で音声を取り出し」
- 「BGMだけ欲しい」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "音声をMP3で抽出" -i input.mp4 -o audio.mp3
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -vn -acodec libmp3lame -q:a 2 audio.mp3
```

---

### 3.2 音声削除（無音動画）

**自然言語指示例**:
- 「音声を消して」
- 「無音動画にして」
- 「映像だけにして」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "音声を削除" -i input.mp4 -o silent.mp4
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -an -c:v copy silent.mp4
```

---

### 3.3 音量調整

**自然言語指示例**:
- 「音量を2倍に」
- 「音を小さくして」
- 「音量を正規化」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "音量を2倍に" -i input.mp4 -o louder.mp4
```

---

## 4. 自動分析・抽出

### 4.1 文字起こし

**自然言語指示例**:
- 「この動画を文字起こしして」
- 「何を話してるか教えて」
- 「書き起こしテキストが欲しい」

**使用ツール**: Whisper（Python直接）

**実行**:
```python
from utils.whisper_wrapper import WhisperWrapper

whisper = WhisperWrapper(model="base")
segments = whisper.transcribe("video.mp4", language="ja")

for seg in segments:
    print(f"[{seg['start']:.1f}s] {seg['text']}")
```

---

### 4.2 動画→要約テキスト

**自然言語指示例**:
- 「この動画の内容を要約して」
- 「何について話してるかまとめて」

**使用ツール**: Whisper → LLM

**手順**:
1. Whisperで文字起こし
2. 文字起こしテキストをLLMに渡して要約

```python
from utils.whisper_wrapper import WhisperWrapper
from utils.llm_wrapper import LLMWrapper

# 1. 文字起こし
whisper = WhisperWrapper()
segments = whisper.transcribe("video.mp4")
transcript = " ".join(seg["text"] for seg in segments)

# 2. LLMで要約
llm = LLMWrapper()
summary = llm.generate(f"以下の文字起こしを箇条書きで要約:\n{transcript}")
print(summary)
```

---

### 4.3 章立て/チャプター提案

**自然言語指示例**:
- 「YouTube用のチャプターを作って」
- 「話題が変わるポイントを教えて」
- 「タイムスタンプ付きの目次が欲しい」

**使用ツール**: Whisper → LLM

**手順**:
1. 文字起こし
2. LLMに「話題の変わり目」を検出させる
3. YouTube形式のタイムスタンプ出力

**LLMプロンプト例**:
```
以下の文字起こしから、話題が変わるポイントを特定し、
YouTube用チャプター形式で出力してください。

形式:
00:00 オープニング
01:30 話題1
05:45 話題2
...

文字起こし:
{transcript}
```

---

### 4.4 サムネ候補フレーム抽出

**自然言語指示例**:
- 「サムネに使えそうなフレームを抽出して」
- 「表情が良いシーンの画像が欲しい」

**使用ツール**: ffmpeg-assistant（複数フレーム抽出）

**実行**:
```bash
# 10秒ごとにフレーム抽出
python main.py ffmpeg "10秒ごとにフレームを画像として抽出" -i input.mp4
```

**生成コマンド例**:
```
ffmpeg -i input.mp4 -vf "fps=1/10" thumb_%03d.jpg
```

---

## 5. 配信者向け特化

### 5.1 配信アーカイブ→切り抜き候補

**自然言語指示例**:
- 「この配信から切り抜き候補を出して」
- 「バズりそうな発言を特定して」

**使用ツール**: clip-cutter

**実行**:
```bash
python main.py clip -i archive.mp4 -n 10 -o ./clips
```

**出力確認**:
```bash
cat clips/metadata.json
# 各クリップの start, end, reason が記録されている
```

---

### 5.2 複数動画→ハイライト集

**自然言語指示例**:
- 「この3本の動画からハイライト集を作って」
- 「各動画の面白い部分を1本にまとめて」

**使用ツール**: clip-cutter × N → ffmpeg結合

**手順**:
1. 各動画でclip-cutter実行
2. 切り出されたクリップをffmpegで結合

```bash
# 1. 各動画からバズ部分抽出
python main.py clip -i video1.mp4 -n 2 -o ./clips1
python main.py clip -i video2.mp4 -n 2 -o ./clips2
python main.py clip -i video3.mp4 -n 2 -o ./clips3

# 2. ファイルリスト作成
echo "file 'clips1/clip_001.mp4'" > list.txt
echo "file 'clips2/clip_001.mp4'" >> list.txt
echo "file 'clips3/clip_001.mp4'" >> list.txt

# 3. 結合
ffmpeg -f concat -safe 0 -i list.txt -c copy highlight.mp4
```

---

### 5.3 A/Bテスト用複数パターン

**自然言語指示例**:
- 「切り出しパターンを3種類作って」
- 「別の切り口でも抽出してみて」

**手順**:
clip-cutterのパラメータを変えて複数回実行

```bash
# パターンA: 短め（15-30秒）
python main.py clip -i video.mp4 -n 5 --min-duration 15 --max-duration 30 -o ./pattern_a

# パターンB: 長め（45-90秒）
python main.py clip -i video.mp4 -n 3 --min-duration 45 --max-duration 90 -o ./pattern_b
```

---

## 6. 変則・応用技

### 6.1 バズ判定基準カスタマイズ

**デフォルトのバズ判定基準**:
- 逆張り・意外な主張
- 強い言い切り
- 面白い言い回し
- 感情的なピーク
- 議論を呼びそうな内容

**カスタマイズ方法**:
`modules/clip_cutter/analyzer.py` の `ANALYSIS_USER_PROMPT` を編集

**例: 教育的に重要な部分を抽出**:
```
【判定基準】
- 分かりやすい説明
- 重要な概念の定義
- 具体例を使った解説
- 結論・まとめ
```

**例: 炎上リスク検出**:
```
【判定基準】
- 誤解を招きそうな表現
- 差別的に聞こえる可能性
- 事実と異なる主張
- 特定の人物・団体への批判
```

---

### 6.2 逆再生/スロー/倍速

**自然言語指示例**:
- 「逆再生にして」
- 「スローモーションで」
- 「2倍速にして」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "2倍速にして" -i input.mp4 -o fast.mp4
python main.py ffmpeg "0.5倍速のスローモーションに" -i input.mp4 -o slow.mp4
python main.py ffmpeg "逆再生" -i input.mp4 -o reverse.mp4
```

---

### 6.3 レトロ風加工

**自然言語指示例**:
- 「VHS風に加工して」
- 「古い映画みたいにして」
- 「ノイズを入れて」

**使用ツール**: ffmpeg-assistant

**実行**:
```bash
python main.py ffmpeg "VHS風のノイズと色褪せを追加" -i input.mp4 -o retro.mp4
```

---

### 6.4 動画比較レポート

**自然言語指示例**:
- 「この2つの動画の違いを教えて」
- 「どっちが画質いい？」

**使用ツール**: ffprobe → LLM

```python
from utils.ffmpeg_wrapper import FFmpegWrapper
from utils.llm_wrapper import LLMWrapper

info1 = FFmpegWrapper.get_file_info("video1.mp4")
info2 = FFmpegWrapper.get_file_info("video2.mp4")

llm = LLMWrapper()
report = llm.generate(f"""
以下の2つの動画を比較してレポートしてください:

動画1: {info1}
動画2: {info2}
""")
print(report)
```

---

## 7. 連携コンボ

### 7.1 バズ部分→縦動画化

**目的**: 配信アーカイブからTikTok/Shorts用縦動画を自動生成

**手順**:
```bash
# 1. バズ部分抽出
python main.py clip -i archive.mp4 -n 5 -o ./clips

# 2. 各クリップを縦動画化
for f in ./clips/clip_*.mp4; do
  python main.py ffmpeg "9:16の縦動画にクロップ" -i "$f" -o "${f%.mp4}_vertical.mp4" -y
done
```

---

### 7.2 長尺→章立て→タイムスタンプ

**目的**: 長い動画にYouTube用チャプターを自動生成

**手順**:
1. Whisperで全編文字起こし
2. LLMに章立て依頼
3. YouTube説明欄用フォーマットで出力

---

### 7.3 フィラー除去（えー、あのー削除）

**目的**: ポッドキャスト等からフィラー語を自動カット

**手順**:
1. Whisperで文字起こし（タイムスタンプ付き）
2. フィラー語を含むセグメントを特定
3. それ以外の部分を結合

---

### 7.4 Gemini Pro連携（映像込み判断）

**目的**: 映像+音声を含めた判断が必要な場合、Gemini Proを「動画の目」として使い、Claudeで編集判断

**いつ使うか**:
- 表情や動きが重要な動画（リアクション系、芸人等）
- テロップや字幕の読み取りが必要
- 音声だけでは判断しづらい内容

**コスト比較**:
| 方法 | コスト | 判断材料 |
|------|--------|----------|
| Whisper+Claude | 無料（ローカル）+ Claude API | 音声のみ |
| Gemini Pro契約 | 月額固定 | **映像+音声** |
| Gemini API | 10分で12〜54円 | 映像+音声 |

**推奨**: Gemini Pro契約での手動運用（月額固定でトークン気にしない）

---

**ワークフロー**:

```
【Step 1】Gemini Proに動画アップロード

【Step 2】詳細記述プロンプト（コピペ用）:
---
この動画の内容を詳細に記述してください。

【出力形式】
タイムスタンプごとに以下を記載:
- 時刻（MM:SS）
- 発言内容（そのまま書き起こし）
- 表情・動き・トーン
- 場の雰囲気
- 特記事項（笑い、驚き、強調など）

【例】
00:15 | 「いや絶対おかしいでしょ」| 眉をひそめて首を振る、声のトーン上がる | やや緊張感 | 強い否定
01:30 | 「これマジで言ってる？」| 目を見開いて笑う | 場が和む | ツッコミ、笑い起きる

全編について詳細に記述してください。
---

【Step 3】Gemini出力をClaudeに渡す

【Step 4】Claudeへのプロンプト例:
---
以下はGeminiによる動画の詳細記述です。
この中からバズりそうな部分を5箇所特定し、
タイムスタンプと理由を教えてください。

{Geminiの出力をここに貼り付け}
---

【Step 5】特定されたタイムスタンプでffmpeg-assistant実行
python main.py ffmpeg "00:15から00:45まで切り出し" -i video.mp4 -o clip1.mp4
```

---

**Geminiへの追加プロンプト例**:

バズ箇所直接特定:
```
この動画からSNSでバズりそうな部分を5箇所、
タイムスタンプと理由付きで教えてください。
映像の表情や動きも判断材料にしてください。
```

章立て:
```
この動画の内容を章立てして、
YouTube説明欄用のタイムスタンプ形式で出力してください。
```

サムネ候補:
```
この動画でサムネイルに使えそうなフレームを
5箇所タイムスタンプで教えてください。
表情が良い、インパクトがある場面を選んでください。
```

---

## 8. 将来拡張（未実装）

| 機能 | 必要な追加 | 備考 |
|------|-----------|------|
| 字幕自動焼き込み | SRT生成 + FFmpeg ASS | Whisper出力→SRT変換→焼込 |
| リアルタイム配信字幕 | faster-whisper + OBS | WebSocket連携 |
| 顔認識シーン抽出 | OpenCV/dlib | 特定人物が映るシーン |
| 自動BGM挿入 | シーン感情判定 + 音源ライブラリ | 商用利用可能音源必要 |
| OCR（動画内テキスト認識） | Tesseract | テロップ読み取り |

---

## 9. トラブルシューティング

### ffmpegコマンドが失敗する

```bash
# dry-runで生成コマンドだけ確認
python main.py ffmpeg "指示" -i input.mp4 --dry-run
```

### Whisperが遅い

```python
# 軽量モデルに変更
whisper = WhisperWrapper(model="tiny")  # tiny < base < small < medium < large
```

### APIキーエラー

```bash
export ANTHROPIC_API_KEY="sk-ant-..."
```

---

*スッラ*
